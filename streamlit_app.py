import streamlit as st
from typing import Dict, Any
import time
from dotenv import load_dotenv
from src.graph import app
from src.utils.ui_components import (
    apply_custom_css, 
    stream_response, 
    get_faq_data, 
    generate_static_faq_response,
    is_follow_up_to_faq,
    create_pipeline_context
)
from config.settings import (
    STREAMLIT_CONFIG,
    HOSPITAL_INFO,
    HOSPITAL_SERVICES,
    SAMPLE_FAQ_QUESTIONS,
    POPULAR_QUESTIONS,
    LLM_CONFIG
)

# Load environment variables
load_dotenv()

# Page configuration
st.set_page_config(**STREAMLIT_CONFIG)

# Apply custom CSS styling
apply_custom_css()

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "conversation_count" not in st.session_state:
    st.session_state.conversation_count = 0
if "user_feedback" not in st.session_state:
    st.session_state.user_feedback = {}
if "message_counter" not in st.session_state:
    st.session_state.message_counter = 0
if "faq_data" not in st.session_state:
    st.session_state.faq_data = get_faq_data()
if "pending_faq_response" not in st.session_state:
    st.session_state.pending_faq_response = None
if "user_has_interacted" not in st.session_state:
    st.session_state.user_has_interacted = False
if "last_processed_faq" not in st.session_state:
    st.session_state.last_processed_faq = None


# Sidebar
with st.sidebar:
    st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
    
    # Quick Access Information - Always visible
    st.header("ğŸ¥ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰")
    
    st.markdown("### ÙˆØµÙˆÙ„ Ø³Ø±ÙŠØ¹")
    st.markdown(f"ğŸ“ **Ø§Ù„Ù…ÙˆÙ‚Ø¹:** {HOSPITAL_INFO['location']}")
    st.markdown(f"ğŸ“ **Ø§Ù„Ø·ÙˆØ§Ø±Ø¦:** {HOSPITAL_INFO['emergency_number']}")
    st.markdown(f"ğŸ•’ **Ø§Ù„Ø²ÙŠØ§Ø±Ø§Øª:** {HOSPITAL_INFO['visiting_hours']}")
    st.markdown(f"ğŸ’Š **Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ©:** {HOSPITAL_INFO['pharmacy_hours']}")
    
    # FAQ Section - Collapsible
    with st.expander("ğŸ“‹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©", expanded=True):
        faqs = SAMPLE_FAQ_QUESTIONS
        
        # FAQ dropdown menu
        dropdown_label = "Ø§Ø®ØªØ± Ø³Ø¤Ø§Ù„Ø§Ù‹:" if not st.session_state.messages else "Ø§Ø¨Ø¯Ø£ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø³Ø¤Ø§Ù„ Ø´Ø§Ø¦Ø¹:"
        
        selected_faq = st.selectbox(
            dropdown_label,
            options=[""] + faqs,
            index=0,
            key="faq_dropdown",
            help="Ø§Ø®ØªØ± Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©" + (" (Ø³ÙŠØ¨Ø¯Ø£ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¬Ø¯ÙŠØ¯Ø©)" if st.session_state.messages else "")
        )
        
        # Handle FAQ selection directly
        if selected_faq and selected_faq != "":
            # Check if this is a different FAQ than the last processed one
            if not hasattr(st.session_state, 'last_processed_faq') or st.session_state.last_processed_faq != selected_faq:
                # Always clear everything and start fresh when FAQ is selected
                st.session_state.messages = []
                st.session_state.conversation_count = 0
                st.session_state.user_feedback = {}
                st.session_state.message_counter = 0
                st.session_state.pending_faq_response = None
                st.session_state.user_has_interacted = True
                st.session_state.last_processed_faq = selected_faq
                
                # Add FAQ as user message
                st.session_state.message_counter += 1
                st.session_state.messages.append({"role": "user", "content": selected_faq, "id": st.session_state.message_counter})
                
                # Generate static response
                static_response = generate_static_faq_response(selected_faq, st.session_state.faq_data)
                st.session_state.pending_faq_response = static_response
                
                # Rerun to update the UI
                st.rerun()
    
    # Hospital Services - Collapsible
    with st.expander("ğŸ¥ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰", expanded=False):
        for service in HOSPITAL_SERVICES:
            st.markdown(f"â€¢ {service}")
    
    # Contact Information - Collapsible
    with st.expander("ğŸ“ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„", expanded=False):
        st.markdown(f"ğŸ“§ **Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ:** {HOSPITAL_INFO['email']}")
        st.markdown(f"ğŸ“± **Ø§Ù„Ù‡Ø§ØªÙ:** {HOSPITAL_INFO['phone']}")
        st.markdown(f"ğŸŒ **Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ:** {HOSPITAL_INFO['website']}")
    
    # Small statistics section in sidebar (only if there are conversations)
    if st.session_state.conversation_count > 0:
        with st.expander("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", expanded=False):
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª", st.session_state.conversation_count, label_visibility="collapsed")
                st.caption("Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„")
            
            with col2:
                positive_feedback = sum(1 for feedback in st.session_state.user_feedback.values() if feedback == "positive")
                st.metric("ğŸ‘", positive_feedback, label_visibility="collapsed")
                st.caption("Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙÙŠØ¯Ø©")
    
    st.markdown('</div>', unsafe_allow_html=True)

# Main content area with compact header
st.markdown('''
<div class="chat-header">
    <h1>ğŸ¥ Hospital AI Assistant Chatbot</h1>
    <p>Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰ Ø£Ùˆ Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯ Ø£Ùˆ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©!</p>
</div>
''', unsafe_allow_html=True)

# Sample questions (only show if user hasn't interacted yet)
if not st.session_state.user_has_interacted and not st.session_state.messages and not st.session_state.pending_faq_response:
    st.markdown("### ğŸ’¡ Ø£Ø³Ø¦Ù„Ø© Ø´Ø§Ø¦Ø¹Ø©")
    sample_questions = POPULAR_QUESTIONS
    
    # Create more compact button layout
    cols = st.columns(len(sample_questions))
    for i, question in enumerate(sample_questions):
        with cols[i]:
            if st.button(question, key=f"sample_{i}", use_container_width=True):
                # Mark that user has interacted
                st.session_state.user_has_interacted = True
                
                # Add FAQ as user message
                st.session_state.message_counter += 1
                st.session_state.messages.append({"role": "user", "content": question, "id": st.session_state.message_counter})
                
                # Generate static response
                static_response = generate_static_faq_response(question, st.session_state.faq_data)
                st.session_state.pending_faq_response = static_response
                st.rerun()
    
    st.markdown("---")
    st.markdown("*ğŸ’¬ Ø£Ùˆ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ ÙÙŠ Ø§Ù„Ù…Ø±Ø¨Ø¹ Ø£Ø¯Ù†Ø§Ù‡...*", help="ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ø§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")

# Handle pending FAQ response
if st.session_state.pending_faq_response:
    # Add static response to messages
    st.session_state.message_counter += 1
    st.session_state.messages.append({
        "role": "assistant", 
        "content": st.session_state.pending_faq_response, 
        "id": st.session_state.message_counter
    })
    st.session_state.conversation_count += 1
    st.session_state.pending_faq_response = None
    st.rerun()

# Display chat messages
for idx, message in enumerate(st.session_state.messages):
    with st.chat_message(message["role"], avatar="ğŸ¥" if message["role"] == "assistant" else "ğŸ‘¤"):
        # Convert newlines to HTML breaks while preserving markdown formatting
        content_with_breaks = message["content"].replace("\n", "<br>")
        st.markdown(content_with_breaks, unsafe_allow_html=True)
        
        # Add small feedback buttons for assistant messages (only show for last message)
        if message["role"] == "assistant" and idx == len(st.session_state.messages) - 1:
            # Use message ID if available, otherwise use index
            msg_id = message.get("id", idx)
            
            # Small, less prominent feedback section
            st.markdown("---")
            col1, col2, col3, col4 = st.columns([1, 1, 1, 9])
            
            with col1:
                if st.button("ğŸ‘", key=f"thumbs_up_{msg_id}", help="Ù…ÙÙŠØ¯", use_container_width=False):
                    st.session_state.user_feedback[msg_id] = "positive"
            
            with col2:
                if st.button("ğŸ‘", key=f"thumbs_down_{msg_id}", help="ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†", use_container_width=False):
                    st.session_state.user_feedback[msg_id] = "negative"


# Chat input
if prompt := st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ Ø¹Ù† Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰..."):
    # Mark that user has interacted
    st.session_state.user_has_interacted = True
    
    # Check if this is a follow-up to an FAQ
    faq_context = is_follow_up_to_faq(st.session_state.messages, prompt)
    
    # Add user message to chat history
    st.session_state.message_counter += 1
    st.session_state.messages.append({"role": "user", "content": prompt, "id": st.session_state.message_counter})
    
    # Display user message
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)
    
    # Generate assistant response
    with st.chat_message("assistant", avatar="ğŸ¥"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
            try:
                # Prepare input for the pipeline
                if faq_context:
                    # This is a follow-up to an FAQ, use context
                    pipeline_input = create_pipeline_context(
                        faq_context["faq_question"],
                        faq_context["faq_answer"],
                        faq_context["user_followup"]
                    )
                else:
                    # Regular question
                    pipeline_input = prompt
                
                # Prepare conversation history (exclude current message)
                conversation_history = [msg for msg in st.session_state.messages[:-1] if msg.get("content")]
                
                # Invoke the chatbot
                result = app.invoke(input={
                    "question": pipeline_input,
                    "conversation_history": conversation_history,
                    "generation_retry_count": 0,  # Initialize retry counter
                    "max_generation_retries": 3   # Set max retries (configurable)
                })
                
                response = result.get("generation", "I'm sorry, I couldn't generate a response. Please try again.")
                

                
                # Stream the response
                message_placeholder = st.empty()
                full_response = stream_response(response, message_placeholder)
                
                # Add assistant response to chat history
                st.session_state.message_counter += 1
                st.session_state.messages.append({"role": "assistant", "content": full_response, "id": st.session_state.message_counter})
                st.session_state.conversation_count += 1
                
            except Exception as e:
                error_message = "Ø£Ø¹ØªØ°Ø±ØŒ Ø£ÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø§Øª ØªÙ‚Ù†ÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø£Ùˆ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰ Ù…Ø¨Ø§Ø´Ø±Ø©."
                st.error(f"Ø®Ø·Ø£: {str(e)}")
                st.markdown(error_message)
                st.session_state.message_counter += 1
                st.session_state.messages.append({"role": "assistant", "content": error_message, "id": st.session_state.message_counter})

# Statistics now moved to sidebar for cleaner interface

# Clear chat button - More compact and better positioned
if st.session_state.messages:
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", key="clear_chat", type="secondary", use_container_width=True):
            st.session_state.messages = []
            st.session_state.conversation_count = 0
            st.session_state.user_feedback = {}
            st.session_state.message_counter = 0
            st.session_state.pending_faq_response = None
            st.session_state.user_has_interacted = False
            st.session_state.last_processed_faq = None
            st.rerun() 